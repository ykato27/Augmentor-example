{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Augmentor_Keras_Array_Data.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykato27/Augmentor-example/blob/main/Augmentor_Keras_Array_Data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "vYP6ELStNEWr"
      },
      "source": [
        "# Augmenting Data from Other Data Sources\n",
        "\n",
        "In this notebook, we will use Augmentor to process images that are stored in memory, and are not read locally from a directory on a hard disk.\n",
        "\n",
        "To demonstrate this, we will use Keras to access the MNIST dataset, which is part of the `keras.datasets` module.\n",
        "\n",
        "Note: you can view a tutorial on using Augmentor with your own images, here <https://github.com/mdbloice/Augmentor/blob/master/notebooks/Augmentor_Keras.ipynb> \n",
        "\n",
        "First we make a number of imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MwUdH8J6NMPG",
        "outputId": "5a7ef7c1-a051-43ca-c99d-bac3976a8f71"
      },
      "source": [
        "!pip install Augmentor"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: Augmentor in /usr/local/lib/python3.7/dist-packages (0.2.8)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (1.19.5)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (4.41.1)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (7.1.2)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "sIGNsaT8NEWx"
      },
      "source": [
        "import Augmentor\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.datasets import mnist\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "e4LYe-AbNEW0"
      },
      "source": [
        "## Get MNIST Data\n",
        "\n",
        "To get the MNIST digit data, we can just called `load_data()` from the `datasets` module. Keras comes with a number of pre-arranged data sets for testing and experimentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "Nz3_v-AENEW1"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "kp2CM4FANEW1"
      },
      "source": [
        "Because we are going to feed the network categorical data, we should convert `y_train` and `y_test`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "3Zn33pRZNEW2"
      },
      "source": [
        "y_train = Augmentor.Pipeline.categorical_labels(y_train)\n",
        "y_test = Augmentor.Pipeline.categorical_labels(y_test)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "pp44sHnmNEW2"
      },
      "source": [
        "### MNIST Data Format\n",
        "\n",
        "Let's examine the type and shape of the MNIST data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPAY3fmANEW3",
        "outputId": "e75e882f-2944-42e1-a57c-ba1263adb93e"
      },
      "source": [
        "num_images, width, height = np.shape(x_train)\n",
        "print(\"The matrix x_train contains %s images, with dimenions of %s x %s.\" % (num_images, width, height))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The matrix x_train contains 60000 images, with dimenions of 28 x 28.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "eqQHl-y0NEW5"
      },
      "source": [
        "If we take a look at one row of the matrix, let's say at index 0, you will see it contains a single image of shape (28, 28):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ouGmbGqNEW5",
        "outputId": "dbaf3716-ef96-46b0-a52f-da07ef85f055"
      },
      "source": [
        "np.shape(x_train[0])"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "R3XOXNM3NEW7"
      },
      "source": [
        "We can use matplotlib's `imshow` function to render this array as an image:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "02_rX7wxNEW7",
        "outputId": "46330016-2a36-448e-8a15-55999e0ee921"
      },
      "source": [
        "plt.imshow(x_train[0], cmap=\"Greys\");"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "qVRcwfcjNEW8"
      },
      "source": [
        "Later, we will pass this entire matrix, containing 60,000 images, to an Augmentor function, which will generate batches of augmented images from this original data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "S0oQjyJ5NEW8"
      },
      "source": [
        "## Create a Pipeline\n",
        "\n",
        "It is perfectly fine to create a pipeline object without needing to point to a directory on your hard drive. Do this if you want to perform an augmentation task on data from another location, such as from the web or another framework such as Keras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "fx1ut3-iNEW9"
      },
      "source": [
        "p = Augmentor.Pipeline()"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "IZ9l8Bf3NEW9"
      },
      "source": [
        "If you then check the pipeline `p`'s status, you will see it has no images or classes associated with it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlcaxlzlNEW9",
        "outputId": "baf50578-52ed-4889-d271-c8bce64ff7f1"
      },
      "source": [
        "p.status()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Operations: 0\n",
            "Images: 0\n",
            "\n",
            "You can remove operations using the appropriate index and the remove_operation(index) function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "zeWDnsAONEW-"
      },
      "source": [
        "Adding operations is done as normal: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXSDxfUJNEW-",
        "outputId": "965b625a-8ba9-48f7-af38-6abe04ae9b84"
      },
      "source": [
        "p.rotate(probability=1, max_left_rotation=5, max_right_rotation=5)\n",
        "p.status()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Operations: 1\n",
            "\t0: RotateRange (probability=1 max_left_rotation=-5 max_right_rotation=5 )\n",
            "Images: 0\n",
            "\n",
            "You can remove operations using the appropriate index and the remove_operation(index) function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "1xQNPBN2NEW_"
      },
      "source": [
        "## Design a Neural Network\n",
        "\n",
        "We will use a simple convolutional neural network using Keras to train a model using the augmented MNIST data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "3WtlN3CaNEW_"
      },
      "source": [
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "DXJzUzCQNEW_"
      },
      "source": [
        "Once a network has been defined, you can compile it so that the model is ready to be trained with data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "vkwr5hzNNEXA"
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "fyT0McvGNEXA"
      },
      "source": [
        "Now that the network is ready, we can create a generator using Augmentor, and pass this generator to the neural network created above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "dz751SksNEXA"
      },
      "source": [
        "## Create a Generator\n",
        "\n",
        "Now, you can use the MNIST data you gathered earlier and use this to create an generator. The generator will augment the data that you pass to it indefinitely and this can be fed into a neural network in order to train it. In this case we will use the images stored in the matrix `x_train` and their corresponding labels stored in the `y_train` array.\n",
        "\n",
        "We will use the generator later, so we will stored in a variable `g`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "B4LSW3hWNEXA"
      },
      "source": [
        "batch_size = 128\n",
        "g = p.keras_generator_from_array(x_train, y_train, batch_size=10)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "pZ662CzRNEXB"
      },
      "source": [
        "We can take a look at what the generator outputs (the generator returns a batch of images and a batch of corresponding labels as a tuple):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "collapsed": true,
        "deletable": true,
        "editable": true,
        "id": "U1xSprKENEXB"
      },
      "source": [
        "X, y = next(g)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "hH3Nl89eNEXB"
      },
      "source": [
        "Let's take a look at the ouput of one image, again using index 0 from the batch of images returned by the generator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "UwXP9_SyNEXC",
        "outputId": "9571f815-4f03-4f61-b100-43dd99bf7f31"
      },
      "source": [
        "plt.imshow(X[0].reshape(28,28), cmap=\"Greys\")"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f184873a190>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "z-YWTSMSNEXC"
      },
      "source": [
        "It's label should also correspond to the image shown above, which we can access using `y`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoXam30iNEXC",
        "outputId": "6d874aa6-0f92-4390-d29a-685f85fc1619"
      },
      "source": [
        "print(\"The image above has the label %s.\" % int(np.nonzero(y[0])[0]))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The image above has the label 1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": true,
        "editable": true,
        "id": "YeTg9BI1NEXD"
      },
      "source": [
        "## Fit the Model using the Generator\n",
        "\n",
        "Now we can fit the model using our generator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "deletable": true,
        "editable": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pHnAGQfNEXD",
        "outputId": "97582ec8-1759-451a-f2c6-91b9d62d32f0"
      },
      "source": [
        "h = model.fit_generator(g, steps_per_epoch=len(x_train)/batch_size, epochs=10, verbose=1)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "468/468 [==============================] - 19s 37ms/step - loss: 2.2963 - accuracy: 0.1220\n",
            "Epoch 2/10\n",
            "468/468 [==============================] - 18s 38ms/step - loss: 2.2784 - accuracy: 0.1501\n",
            "Epoch 3/10\n",
            "468/468 [==============================] - 18s 38ms/step - loss: 2.2596 - accuracy: 0.1865\n",
            "Epoch 4/10\n",
            "468/468 [==============================] - 18s 38ms/step - loss: 2.2357 - accuracy: 0.2484\n",
            "Epoch 5/10\n",
            "468/468 [==============================] - 18s 38ms/step - loss: 2.2222 - accuracy: 0.2590\n",
            "Epoch 6/10\n",
            "468/468 [==============================] - 18s 38ms/step - loss: 2.2009 - accuracy: 0.2876\n",
            "Epoch 7/10\n",
            "468/468 [==============================] - 18s 38ms/step - loss: 2.1703 - accuracy: 0.3295\n",
            "Epoch 8/10\n",
            "468/468 [==============================] - 18s 39ms/step - loss: 2.1511 - accuracy: 0.3546\n",
            "Epoch 9/10\n",
            "468/468 [==============================] - 18s 38ms/step - loss: 2.1196 - accuracy: 0.3767\n",
            "Epoch 10/10\n",
            "468/468 [==============================] - 18s 38ms/step - loss: 2.0842 - accuracy: 0.4133\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hCkV2XDQNEXD"
      },
      "source": [
        "## Summary\n",
        "You can use data loaded into memory rather than reading from disk using Augmentor's `keras_generator_from_array` function. This has the advantage that the online augmentation is much faster than when reading from disk."
      ]
    }
  ]
}