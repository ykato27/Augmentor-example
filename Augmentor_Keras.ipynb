{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Augmentor_Keras.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ykato27/Augmentor-example/blob/main/Augmentor_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOaOjmukPWjg"
      },
      "source": [
        "# Training a Neural Network using Augmentor and Keras\n",
        "\n",
        "In this notebook, we will train a simple convolutional neural network on the MNIST dataset using Augmentor to augment images on the fly using a generator.\n",
        "\n",
        "## Import Required Libraries\n",
        "\n",
        "We start by making a number of imports:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZpq5fKpPaDd",
        "outputId": "187e44af-b4e3-4e73-9d56-e24f3536299d"
      },
      "source": [
        "!pip install Augmentor"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Augmentor\n",
            "  Downloading Augmentor-0.2.8-py2.py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: Pillow>=5.2.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (7.1.2)\n",
            "Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (1.19.5)\n",
            "Requirement already satisfied: future>=0.16.0 in /usr/local/lib/python3.7/dist-packages (from Augmentor) (0.16.0)\n",
            "Installing collected packages: Augmentor\n",
            "Successfully installed Augmentor-0.2.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YEiTOyp7PWjm"
      },
      "source": [
        "import Augmentor\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19b1kJMPPWjp"
      },
      "source": [
        "## Define a Convolutional Neural Network\n",
        "\n",
        "Once the libraries have been imported, we define a small convolutional neural network. See the Keras documentation for details of this network: <https://github.com/fchollet/keras/blob/master/examples/mnist_cnn.py> \n",
        "\n",
        "It is a three layer deep neural network, consisting of 2 convolutional layers and a fully connected layer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBOEcY6gPWjq"
      },
      "source": [
        "num_classes = 10\n",
        "input_shape = (28, 28, 1)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vwKjL2XPWjq"
      },
      "source": [
        "Once a network has been defined, you can compile it so that the model is ready to be trained with data:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAeUz-ATPWjr"
      },
      "source": [
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gulRKKfIPWjs"
      },
      "source": [
        "You can view a summary of the network using the `summary()` function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGTWDo4ePWjt",
        "outputId": "7c0653a7-2fe6-47e3-f30d-513ec6c210a0"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 128)               1179776   \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                1290      \n",
            "=================================================================\n",
            "Total params: 1,199,882\n",
            "Trainable params: 1,199,882\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEURJkPaPWjt"
      },
      "source": [
        "## Use Augmentor to Scan Directory for Data\n",
        "\n",
        "Now we will use Augmentor to scan a directory containing our data that we will eventually feed into the neural network in order to train it. \n",
        "\n",
        "When you point a pipeline to a directory, it will scan each subdirectory and treat each subdirectory as a class for your machine learning problem. \n",
        "\n",
        "For example, within the directory `mnist`, there are subdirectories for each digit:\n",
        "\n",
        "```\n",
        "mnist/\n",
        "├── 0/\n",
        "│   ├── 0001.png\n",
        "│   ├── 0002.png\n",
        "│   ├── ...\n",
        "│   └── 5985.png\n",
        "├── 1/\n",
        "│   ├── 0001.png\n",
        "│   ├── 0002.png\n",
        "│   ├── ...\n",
        "│   └── 6101.png\n",
        "├── 2/\n",
        "│   ├── 0000.png\n",
        "│   ├── 0001.png\n",
        "│   ├── ...\n",
        "│   └── 5801.png\n",
        "│ ...\n",
        "├── 9/\n",
        "│   ├── 0001.png\n",
        "│   ├── 0002.png\n",
        "│   ├── ...\n",
        "│   └── 6001.png\n",
        "└\n",
        "```\n",
        "\n",
        "The directory `0` contains all the images corresponding to the 0 class.\n",
        "\n",
        "To get the data, we can use `wget` (this may not work under Windows):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GD0niOjCPWju",
        "outputId": "1e563273-313c-48b5-a818-809c8b7b7b98"
      },
      "source": [
        "!wget https://rawgit.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
        "!tar -xf mnist_png.tar.gz"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-07 06:13:08--  https://rawgit.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
            "Resolving rawgit.com (rawgit.com)... 104.21.63.184, 172.67.149.80, 2606:4700:3032::6815:3fb8, ...\n",
            "Connecting to rawgit.com (rawgit.com)|104.21.63.184|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://raw.githubusercontent.com/myleott/mnist_png/master/mnist_png.tar.gz [following]\n",
            "--2021-08-07 06:13:08--  https://raw.githubusercontent.com/myleott/mnist_png/master/mnist_png.tar.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15683414 (15M) [application/octet-stream]\n",
            "Saving to: ‘mnist_png.tar.gz’\n",
            "\n",
            "mnist_png.tar.gz    100%[===================>]  14.96M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-08-07 06:13:08 (103 MB/s) - ‘mnist_png.tar.gz’ saved [15683414/15683414]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkXRrVpMPWjv"
      },
      "source": [
        "After the MNIST data has downloaded, we can instantiate a `Pipeline` object in the `training` directory to add the images to the current pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXdWvGMpPWjv",
        "outputId": "ffad73f2-3777-4e66-e502-d60ceca1503f"
      },
      "source": [
        "p = Augmentor.Pipeline(\"mnist_png/training\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Initialised with 60000 image(s) found.\n",
            "Output directory set to mnist_png/training/output."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qI7t6OPjPWjw"
      },
      "source": [
        "## Add Operations to the Pipeline\n",
        "\n",
        "Now that a pipeline object `p` has been created, we can add operations to the pipeline. Below we add several simple  operations:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WLu6sRhPWjw"
      },
      "source": [
        "p.flip_top_bottom(probability=0.1)\n",
        "p.rotate(probability=0.3, max_left_rotation=5, max_right_rotation=5)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9C9OqTfPWjx"
      },
      "source": [
        "You can view the status of pipeline using the `status()` function, which shows information regarding the number of classes in the pipeline, the number of images, and what operations have been added to the pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-atxkY0vPWjx",
        "outputId": "3511b047-ceda-4773-c1a1-1a4d0937a05b"
      },
      "source": [
        "p.status()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Operations: 2\n",
            "\t0: Flip (probability=0.1 top_bottom_left_right=TOP_BOTTOM )\n",
            "\t1: RotateRange (probability=0.3 max_left_rotation=-5 max_right_rotation=5 )\n",
            "Images: 60000\n",
            "Classes: 10\n",
            "\tClass index: 0 Class label: 0 \n",
            "\tClass index: 1 Class label: 1 \n",
            "\tClass index: 2 Class label: 2 \n",
            "\tClass index: 3 Class label: 3 \n",
            "\tClass index: 4 Class label: 4 \n",
            "\tClass index: 5 Class label: 5 \n",
            "\tClass index: 6 Class label: 6 \n",
            "\tClass index: 7 Class label: 7 \n",
            "\tClass index: 8 Class label: 8 \n",
            "\tClass index: 9 Class label: 9 \n",
            "Dimensions: 1\n",
            "\tWidth: 28 Height: 28\n",
            "Formats: 1\n",
            "\t PNG\n",
            "\n",
            "You can remove operations using the appropriate index and the remove_operation(index) function.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybWfztUCPWjy"
      },
      "source": [
        "## Creating a Generator\n",
        "\n",
        "A generator will create images indefinitely, and we can use this generator as input into the model created above. The generator is created with a user-defined batch size, which we define here in a variable named `batch_size`. This is used later to define number of steps per epoch, so it is best to keep it stored as a variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihOVcrg6PWjy"
      },
      "source": [
        "batch_size = 128\n",
        "g = p.keras_generator(batch_size=batch_size)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKLeFjYuPWjz"
      },
      "source": [
        "The generator can now be used to created augmented data. In Python, generators are invoked using the `next()` function - the Augmentor generators will return images indefinitely, and so `next()` can be called as often as required. \n",
        "\n",
        "You can view the output of generator manually:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AYIncTqPWjz"
      },
      "source": [
        "images, labels = next(g)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UNQT3BvmPWj0"
      },
      "source": [
        "Images, and their labels, are returned in batches of the size defined above by `batch_size`. The `image_batch` variable is a tuple, containing the augmentented images and their corresponding labels.\n",
        "\n",
        "To see the label of the first image returned by the generator you can use the array's index:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TSq63jHnPWj0",
        "outputId": "655a1fe1-e2be-48e2-a9ba-60d5655a5c3f"
      },
      "source": [
        "print(labels[0])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7o6OzD0hPWj0"
      },
      "source": [
        "Or preview the images using Matplotlib (the image should be a 5, according to the label information above):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "dhpusII1PWj1",
        "outputId": "66a46e0d-dcdd-4447-a8c6-860f73be1fe3"
      },
      "source": [
        "plt.imshow(images[0].reshape(28, 28), cmap=\"Greys\");"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj2NF3w_PWj1"
      },
      "source": [
        "## Train the Network\n",
        "\n",
        "We train the network by passing the generator, `g`, to the model's fit function. In Keras, if a generator is used we used the `fit_generator()` function as opposed to the standard `fit()` function. Also, the steps per epoch should roughly equal the total number of images in your dataset divided by the `batch_size`.\n",
        "\n",
        "Training the network over 5 epochs, we get the following output:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGx4uZtePWj2",
        "outputId": "e73e9ba0-5d31-4fa2-aa93-bedccf9cb4de"
      },
      "source": [
        "h = model.fit_generator(g, steps_per_epoch=len(p.augmentor_images)/batch_size, epochs=5, verbose=1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "468/468 [==============================] - 174s 336ms/step - loss: 2.2968 - accuracy: 0.1281\n",
            "Epoch 2/5\n",
            "468/468 [==============================] - 157s 335ms/step - loss: 2.2485 - accuracy: 0.2084\n",
            "Epoch 3/5\n",
            "468/468 [==============================] - 157s 335ms/step - loss: 2.1905 - accuracy: 0.3034\n",
            "Epoch 4/5\n",
            "468/468 [==============================] - 156s 334ms/step - loss: 2.1180 - accuracy: 0.3793\n",
            "Epoch 5/5\n",
            "468/468 [==============================] - 156s 332ms/step - loss: 2.0245 - accuracy: 0.4433\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1CgHgeUPWj2"
      },
      "source": [
        "## Summary\n",
        "\n",
        "Using Augmentor with Keras means only that you need to create a generator when you are finished creating your pipeline. This has the advantage that no images need to be saved to disk and are augmented on the fly."
      ]
    }
  ]
}